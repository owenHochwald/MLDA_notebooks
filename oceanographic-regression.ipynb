{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:31.572803Z","iopub.status.busy":"2024-06-17T18:23:31.572475Z","iopub.status.idle":"2024-06-17T18:23:31.604866Z","shell.execute_reply":"2024-06-17T18:23:31.603387Z","shell.execute_reply.started":"2024-06-17T18:23:31.572774Z"},"trusted":true},"outputs":[],"source":["# import libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score"]},{"cell_type":"markdown","metadata":{},"source":["# Data Processing"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:31.607457Z","iopub.status.busy":"2024-06-17T18:23:31.606597Z","iopub.status.idle":"2024-06-17T18:23:37.729419Z","shell.execute_reply":"2024-06-17T18:23:37.728193Z","shell.execute_reply.started":"2024-06-17T18:23:31.607423Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\o\\AppData\\Local\\Temp\\ipykernel_26024\\1719653949.py:1: DtypeWarning: Columns (47,73) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv('../datasets/ocean_bottle/bottle.csv')\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cst_Cnt</th>\n","      <th>Btl_Cnt</th>\n","      <th>Sta_ID</th>\n","      <th>Depth_ID</th>\n","      <th>Depthm</th>\n","      <th>T_degC</th>\n","      <th>Salnty</th>\n","      <th>O2ml_L</th>\n","      <th>STheta</th>\n","      <th>O2Sat</th>\n","      <th>Oxy_µmol/Kg</th>\n","      <th>BtlNum</th>\n","      <th>RecInd</th>\n","      <th>T_prec</th>\n","      <th>T_qual</th>\n","      <th>S_prec</th>\n","      <th>S_qual</th>\n","      <th>P_qual</th>\n","      <th>O_qual</th>\n","      <th>SThtaq</th>\n","      <th>O2Satq</th>\n","      <th>ChlorA</th>\n","      <th>Chlqua</th>\n","      <th>Phaeop</th>\n","      <th>Phaqua</th>\n","      <th>PO4uM</th>\n","      <th>PO4q</th>\n","      <th>SiO3uM</th>\n","      <th>SiO3qu</th>\n","      <th>NO2uM</th>\n","      <th>NO2q</th>\n","      <th>NO3uM</th>\n","      <th>NO3q</th>\n","      <th>NH3uM</th>\n","      <th>NH3q</th>\n","      <th>C14As1</th>\n","      <th>C14A1p</th>\n","      <th>C14A1q</th>\n","      <th>C14As2</th>\n","      <th>C14A2p</th>\n","      <th>C14A2q</th>\n","      <th>DarkAs</th>\n","      <th>DarkAp</th>\n","      <th>DarkAq</th>\n","      <th>MeanAs</th>\n","      <th>MeanAp</th>\n","      <th>MeanAq</th>\n","      <th>IncTim</th>\n","      <th>LightP</th>\n","      <th>R_Depth</th>\n","      <th>R_TEMP</th>\n","      <th>R_POTEMP</th>\n","      <th>R_SALINITY</th>\n","      <th>R_SIGMA</th>\n","      <th>R_SVA</th>\n","      <th>R_DYNHT</th>\n","      <th>R_O2</th>\n","      <th>R_O2Sat</th>\n","      <th>R_SIO3</th>\n","      <th>R_PO4</th>\n","      <th>R_NO3</th>\n","      <th>R_NO2</th>\n","      <th>R_NH4</th>\n","      <th>R_CHLA</th>\n","      <th>R_PHAEO</th>\n","      <th>R_PRES</th>\n","      <th>R_SAMP</th>\n","      <th>DIC1</th>\n","      <th>DIC2</th>\n","      <th>TA1</th>\n","      <th>TA2</th>\n","      <th>pH2</th>\n","      <th>pH1</th>\n","      <th>DIC Quality Comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n","      <td>0</td>\n","      <td>10.50</td>\n","      <td>33.440</td>\n","      <td>NaN</td>\n","      <td>25.649</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>10.50</td>\n","      <td>10.50</td>\n","      <td>33.440</td>\n","      <td>25.64</td>\n","      <td>233.0</td>\n","      <td>0.00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n","      <td>8</td>\n","      <td>10.46</td>\n","      <td>33.440</td>\n","      <td>NaN</td>\n","      <td>25.656</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.440</td>\n","      <td>25.65</td>\n","      <td>232.5</td>\n","      <td>0.01</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n","      <td>10</td>\n","      <td>10.46</td>\n","      <td>33.437</td>\n","      <td>NaN</td>\n","      <td>25.654</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.437</td>\n","      <td>25.65</td>\n","      <td>232.8</td>\n","      <td>0.02</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0019A-3</td>\n","      <td>19</td>\n","      <td>10.45</td>\n","      <td>33.420</td>\n","      <td>NaN</td>\n","      <td>25.643</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>19.0</td>\n","      <td>10.45</td>\n","      <td>10.45</td>\n","      <td>33.420</td>\n","      <td>25.64</td>\n","      <td>234.1</td>\n","      <td>0.04</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>19</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0020A-7</td>\n","      <td>20</td>\n","      <td>10.45</td>\n","      <td>33.421</td>\n","      <td>NaN</td>\n","      <td>25.643</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>20.0</td>\n","      <td>10.45</td>\n","      <td>10.45</td>\n","      <td>33.421</td>\n","      <td>25.64</td>\n","      <td>234.0</td>\n","      <td>0.04</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>20</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Cst_Cnt  Btl_Cnt       Sta_ID                                Depth_ID  \\\n","0        1        1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3   \n","1        1        2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3   \n","2        1        3  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7   \n","3        1        4  054.0 056.0  19-4903CR-HY-060-0930-05400560-0019A-3   \n","4        1        5  054.0 056.0  19-4903CR-HY-060-0930-05400560-0020A-7   \n","\n","   Depthm  T_degC  Salnty  O2ml_L  STheta  O2Sat  Oxy_µmol/Kg  BtlNum  RecInd  \\\n","0       0   10.50  33.440     NaN  25.649    NaN          NaN     NaN       3   \n","1       8   10.46  33.440     NaN  25.656    NaN          NaN     NaN       3   \n","2      10   10.46  33.437     NaN  25.654    NaN          NaN     NaN       7   \n","3      19   10.45  33.420     NaN  25.643    NaN          NaN     NaN       3   \n","4      20   10.45  33.421     NaN  25.643    NaN          NaN     NaN       7   \n","\n","   T_prec  T_qual  S_prec  S_qual  P_qual  O_qual  SThtaq  O2Satq  ChlorA  \\\n","0     1.0     NaN     2.0     NaN     9.0     9.0     NaN     9.0     NaN   \n","1     2.0     NaN     2.0     NaN     9.0     9.0     NaN     9.0     NaN   \n","2     2.0     NaN     3.0     NaN     9.0     9.0     NaN     9.0     NaN   \n","3     2.0     NaN     2.0     NaN     9.0     9.0     NaN     9.0     NaN   \n","4     2.0     NaN     3.0     NaN     9.0     9.0     NaN     9.0     NaN   \n","\n","   Chlqua  Phaeop  Phaqua  PO4uM  PO4q  SiO3uM  SiO3qu  NO2uM  NO2q  NO3uM  \\\n","0     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n","1     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n","2     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n","3     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n","4     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n","\n","   NO3q  NH3uM  NH3q  C14As1  C14A1p  C14A1q  C14As2  C14A2p  C14A2q  DarkAs  \\\n","0   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n","1   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n","2   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n","3   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n","4   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n","\n","   DarkAp  DarkAq  MeanAs  MeanAp  MeanAq IncTim  LightP  R_Depth  R_TEMP  \\\n","0     NaN     9.0     NaN     NaN     9.0    NaN     NaN      0.0   10.50   \n","1     NaN     9.0     NaN     NaN     9.0    NaN     NaN      8.0   10.46   \n","2     NaN     9.0     NaN     NaN     9.0    NaN     NaN     10.0   10.46   \n","3     NaN     9.0     NaN     NaN     9.0    NaN     NaN     19.0   10.45   \n","4     NaN     9.0     NaN     NaN     9.0    NaN     NaN     20.0   10.45   \n","\n","   R_POTEMP  R_SALINITY  R_SIGMA  R_SVA  R_DYNHT  R_O2  R_O2Sat  R_SIO3  \\\n","0     10.50      33.440    25.64  233.0     0.00   NaN      NaN     NaN   \n","1     10.46      33.440    25.65  232.5     0.01   NaN      NaN     NaN   \n","2     10.46      33.437    25.65  232.8     0.02   NaN      NaN     NaN   \n","3     10.45      33.420    25.64  234.1     0.04   NaN      NaN     NaN   \n","4     10.45      33.421    25.64  234.0     0.04   NaN      NaN     NaN   \n","\n","   R_PO4  R_NO3  R_NO2  R_NH4  R_CHLA  R_PHAEO  R_PRES  R_SAMP  DIC1  DIC2  \\\n","0    NaN    NaN    NaN    NaN     NaN      NaN       0     NaN   NaN   NaN   \n","1    NaN    NaN    NaN    NaN     NaN      NaN       8     NaN   NaN   NaN   \n","2    NaN    NaN    NaN    NaN     NaN      NaN      10     NaN   NaN   NaN   \n","3    NaN    NaN    NaN    NaN     NaN      NaN      19     NaN   NaN   NaN   \n","4    NaN    NaN    NaN    NaN     NaN      NaN      20     NaN   NaN   NaN   \n","\n","   TA1  TA2  pH2  pH1 DIC Quality Comment  \n","0  NaN  NaN  NaN  NaN                 NaN  \n","1  NaN  NaN  NaN  NaN                 NaN  \n","2  NaN  NaN  NaN  NaN                 NaN  \n","3  NaN  NaN  NaN  NaN                 NaN  \n","4  NaN  NaN  NaN  NaN                 NaN  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('../datasets/ocean_bottle/bottle.csv')\n","pd.options.display.max_columns = None\n","df.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:37.732179Z","iopub.status.busy":"2024-06-17T18:23:37.731745Z","iopub.status.idle":"2024-06-17T18:23:37.739163Z","shell.execute_reply":"2024-06-17T18:23:37.738060Z","shell.execute_reply.started":"2024-06-17T18:23:37.732140Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(864863, 74)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# 74 columns, 864,863 rows\n","df.shape"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:37.740856Z","iopub.status.busy":"2024-06-17T18:23:37.740492Z","iopub.status.idle":"2024-06-17T18:23:37.962029Z","shell.execute_reply":"2024-06-17T18:23:37.961012Z","shell.execute_reply.started":"2024-06-17T18:23:37.740827Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Cst_Cnt                     0\n","Btl_Cnt                     0\n","Sta_ID                      0\n","Depth_ID                    0\n","Depthm                      0\n","                        ...  \n","TA1                    862779\n","TA2                    864629\n","pH2                    864853\n","pH1                    864779\n","DIC Quality Comment    864808\n","Length: 74, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# how many null values are in our dataset?\n","df.isna().sum() "]},{"cell_type":"markdown","metadata":{},"source":["We see that our data has many columns with substantial amounts of missing values. Let's stick with columns that have fewer than 10% missing data since we have a large number of columns."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:37.965080Z","iopub.status.busy":"2024-06-17T18:23:37.964650Z","iopub.status.idle":"2024-06-17T18:23:38.188977Z","shell.execute_reply":"2024-06-17T18:23:38.187963Z","shell.execute_reply.started":"2024-06-17T18:23:37.965043Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(['Cst_Cnt',\n","  'Btl_Cnt',\n","  'Sta_ID',\n","  'Depth_ID',\n","  'Depthm',\n","  'T_degC',\n","  'Salnty',\n","  'STheta',\n","  'RecInd',\n","  'T_prec',\n","  'S_prec',\n","  'NH3q',\n","  'C14A1q',\n","  'C14A2q',\n","  'DarkAq',\n","  'MeanAq',\n","  'R_Depth',\n","  'R_TEMP',\n","  'R_POTEMP',\n","  'R_SALINITY',\n","  'R_SIGMA',\n","  'R_SVA',\n","  'R_DYNHT',\n","  'R_PRES'],\n"," 24)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["columns = [col for col in df.columns if (df[col].isnull().sum() / df.shape[0]) <= 0.07]\n","columns, len(columns)"]},{"cell_type":"markdown","metadata":{},"source":["We're left with 24 columns out of the 74. For our first pass and to make it simple, we're going to drop the 50 columns that have high amounts of na values. This will give us a quick and easy baseline. If our model preformance is good, we don't need to add in more columns, however, if it's bad we can consider doing more data processing."]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.190640Z","iopub.status.busy":"2024-06-17T18:23:38.190236Z","iopub.status.idle":"2024-06-17T18:23:38.264593Z","shell.execute_reply":"2024-06-17T18:23:38.263479Z","shell.execute_reply.started":"2024-06-17T18:23:38.190605Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cst_Cnt</th>\n","      <th>Btl_Cnt</th>\n","      <th>Sta_ID</th>\n","      <th>Depth_ID</th>\n","      <th>Depthm</th>\n","      <th>T_degC</th>\n","      <th>Salnty</th>\n","      <th>STheta</th>\n","      <th>RecInd</th>\n","      <th>T_prec</th>\n","      <th>S_prec</th>\n","      <th>NH3q</th>\n","      <th>C14A1q</th>\n","      <th>C14A2q</th>\n","      <th>DarkAq</th>\n","      <th>MeanAq</th>\n","      <th>R_Depth</th>\n","      <th>R_TEMP</th>\n","      <th>R_POTEMP</th>\n","      <th>R_SALINITY</th>\n","      <th>R_SIGMA</th>\n","      <th>R_SVA</th>\n","      <th>R_DYNHT</th>\n","      <th>R_PRES</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n","      <td>0</td>\n","      <td>10.50</td>\n","      <td>33.440</td>\n","      <td>25.649</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>10.50</td>\n","      <td>10.50</td>\n","      <td>33.440</td>\n","      <td>25.64</td>\n","      <td>233.0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n","      <td>8</td>\n","      <td>10.46</td>\n","      <td>33.440</td>\n","      <td>25.656</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>8.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.440</td>\n","      <td>25.65</td>\n","      <td>232.5</td>\n","      <td>0.01</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n","      <td>10</td>\n","      <td>10.46</td>\n","      <td>33.437</td>\n","      <td>25.654</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.437</td>\n","      <td>25.65</td>\n","      <td>232.8</td>\n","      <td>0.02</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0019A-3</td>\n","      <td>19</td>\n","      <td>10.45</td>\n","      <td>33.420</td>\n","      <td>25.643</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>19.0</td>\n","      <td>10.45</td>\n","      <td>10.45</td>\n","      <td>33.420</td>\n","      <td>25.64</td>\n","      <td>234.1</td>\n","      <td>0.04</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0020A-7</td>\n","      <td>20</td>\n","      <td>10.45</td>\n","      <td>33.421</td>\n","      <td>25.643</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>20.0</td>\n","      <td>10.45</td>\n","      <td>10.45</td>\n","      <td>33.421</td>\n","      <td>25.64</td>\n","      <td>234.0</td>\n","      <td>0.04</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Cst_Cnt  Btl_Cnt       Sta_ID                                Depth_ID  \\\n","0        1        1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3   \n","1        1        2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3   \n","2        1        3  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7   \n","3        1        4  054.0 056.0  19-4903CR-HY-060-0930-05400560-0019A-3   \n","4        1        5  054.0 056.0  19-4903CR-HY-060-0930-05400560-0020A-7   \n","\n","   Depthm  T_degC  Salnty  STheta  RecInd  T_prec  S_prec  NH3q  C14A1q  \\\n","0       0   10.50  33.440  25.649       3     1.0     2.0   9.0     9.0   \n","1       8   10.46  33.440  25.656       3     2.0     2.0   9.0     9.0   \n","2      10   10.46  33.437  25.654       7     2.0     3.0   9.0     9.0   \n","3      19   10.45  33.420  25.643       3     2.0     2.0   9.0     9.0   \n","4      20   10.45  33.421  25.643       7     2.0     3.0   9.0     9.0   \n","\n","   C14A2q  DarkAq  MeanAq  R_Depth  R_TEMP  R_POTEMP  R_SALINITY  R_SIGMA  \\\n","0     9.0     9.0     9.0      0.0   10.50     10.50      33.440    25.64   \n","1     9.0     9.0     9.0      8.0   10.46     10.46      33.440    25.65   \n","2     9.0     9.0     9.0     10.0   10.46     10.46      33.437    25.65   \n","3     9.0     9.0     9.0     19.0   10.45     10.45      33.420    25.64   \n","4     9.0     9.0     9.0     20.0   10.45     10.45      33.421    25.64   \n","\n","   R_SVA  R_DYNHT  R_PRES  \n","0  233.0     0.00       0  \n","1  232.5     0.01       8  \n","2  232.8     0.02      10  \n","3  234.1     0.04      19  \n","4  234.0     0.04      20  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["#  getting rid of the 50 columns\n","df = df[columns]\n","df.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.267240Z","iopub.status.busy":"2024-06-17T18:23:38.266781Z","iopub.status.idle":"2024-06-17T18:23:38.382178Z","shell.execute_reply":"2024-06-17T18:23:38.381093Z","shell.execute_reply.started":"2024-06-17T18:23:38.267201Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Cst_Cnt           0\n","Btl_Cnt           0\n","Sta_ID            0\n","Depth_ID          0\n","Depthm            0\n","T_degC        10963\n","Salnty        47354\n","STheta        52689\n","RecInd            0\n","T_prec        10963\n","S_prec        47354\n","NH3q          56564\n","C14A1q        16258\n","C14A2q        16240\n","DarkAq        24423\n","MeanAq        24424\n","R_Depth           0\n","R_TEMP        10963\n","R_POTEMP      46047\n","R_SALINITY    47354\n","R_SIGMA       52856\n","R_SVA         52771\n","R_DYNHT       46657\n","R_PRES            0\n","dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# checking null values again\n","df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["We have a large amount of data so we're going to take a quick approach and simply drop the ropws with missing data. This isn't ideal, but for a first iteration of our model, it's a good way to get a baseline. From eariler, we know that none of the columns have no more than 10% missing data, so dropping the rows with missing data should still keep most of the data and preserve the columns."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.383974Z","iopub.status.busy":"2024-06-17T18:23:38.383624Z","iopub.status.idle":"2024-06-17T18:23:38.545326Z","shell.execute_reply":"2024-06-17T18:23:38.544211Z","shell.execute_reply.started":"2024-06-17T18:23:38.383945Z"},"trusted":true},"outputs":[],"source":["df = df.dropna()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.546954Z","iopub.status.busy":"2024-06-17T18:23:38.546629Z","iopub.status.idle":"2024-06-17T18:23:38.646270Z","shell.execute_reply":"2024-06-17T18:23:38.645074Z","shell.execute_reply.started":"2024-06-17T18:23:38.546927Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Cst_Cnt       0\n","Btl_Cnt       0\n","Sta_ID        0\n","Depth_ID      0\n","Depthm        0\n","T_degC        0\n","Salnty        0\n","STheta        0\n","RecInd        0\n","T_prec        0\n","S_prec        0\n","NH3q          0\n","C14A1q        0\n","C14A2q        0\n","DarkAq        0\n","MeanAq        0\n","R_Depth       0\n","R_TEMP        0\n","R_POTEMP      0\n","R_SALINITY    0\n","R_SIGMA       0\n","R_SVA         0\n","R_DYNHT       0\n","R_PRES        0\n","dtype: int64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# checking null values again\n","df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Ahh, beautiful, no missing data!"]},{"cell_type":"markdown","metadata":{},"source":["### Inspecting Column Data Types"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.648227Z","iopub.status.busy":"2024-06-17T18:23:38.647893Z","iopub.status.idle":"2024-06-17T18:23:38.762219Z","shell.execute_reply":"2024-06-17T18:23:38.760872Z","shell.execute_reply.started":"2024-06-17T18:23:38.648201Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 733418 entries, 0 to 864860\n","Data columns (total 24 columns):\n"," #   Column      Non-Null Count   Dtype  \n","---  ------      --------------   -----  \n"," 0   Cst_Cnt     733418 non-null  int64  \n"," 1   Btl_Cnt     733418 non-null  int64  \n"," 2   Sta_ID      733418 non-null  object \n"," 3   Depth_ID    733418 non-null  object \n"," 4   Depthm      733418 non-null  int64  \n"," 5   T_degC      733418 non-null  float64\n"," 6   Salnty      733418 non-null  float64\n"," 7   STheta      733418 non-null  float64\n"," 8   RecInd      733418 non-null  int64  \n"," 9   T_prec      733418 non-null  float64\n"," 10  S_prec      733418 non-null  float64\n"," 11  NH3q        733418 non-null  float64\n"," 12  C14A1q      733418 non-null  float64\n"," 13  C14A2q      733418 non-null  float64\n"," 14  DarkAq      733418 non-null  float64\n"," 15  MeanAq      733418 non-null  float64\n"," 16  R_Depth     733418 non-null  float64\n"," 17  R_TEMP      733418 non-null  float64\n"," 18  R_POTEMP    733418 non-null  float64\n"," 19  R_SALINITY  733418 non-null  float64\n"," 20  R_SIGMA     733418 non-null  float64\n"," 21  R_SVA       733418 non-null  float64\n"," 22  R_DYNHT     733418 non-null  float64\n"," 23  R_PRES      733418 non-null  int64  \n","dtypes: float64(17), int64(5), object(2)\n","memory usage: 139.9+ MB\n"]}],"source":["# we're looking for non continuous values --> \"string\" values\n","df.info()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.766059Z","iopub.status.busy":"2024-06-17T18:23:38.765690Z","iopub.status.idle":"2024-06-17T18:23:38.790926Z","shell.execute_reply":"2024-06-17T18:23:38.789565Z","shell.execute_reply.started":"2024-06-17T18:23:38.766029Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sta_ID</th>\n","      <th>Depth_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>054.0 056.0</td>\n","      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Sta_ID                                Depth_ID\n","0  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3\n","1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3\n","2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df.select_dtypes('object').head(3)"]},{"cell_type":"markdown","metadata":{},"source":["Since these columns appear to just be ID columns and not very informative, we are going to drop them. If our model preformance is poor, we can look to add them back in."]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.792608Z","iopub.status.busy":"2024-06-17T18:23:38.792192Z","iopub.status.idle":"2024-06-17T18:23:38.831082Z","shell.execute_reply":"2024-06-17T18:23:38.829942Z","shell.execute_reply.started":"2024-06-17T18:23:38.792551Z"},"trusted":true},"outputs":[],"source":["df.drop(['Sta_ID','Depth_ID'], inplace=True, axis=1)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.833153Z","iopub.status.busy":"2024-06-17T18:23:38.832771Z","iopub.status.idle":"2024-06-17T18:23:38.858889Z","shell.execute_reply":"2024-06-17T18:23:38.857794Z","shell.execute_reply.started":"2024-06-17T18:23:38.833122Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cst_Cnt</th>\n","      <th>Btl_Cnt</th>\n","      <th>Depthm</th>\n","      <th>T_degC</th>\n","      <th>Salnty</th>\n","      <th>STheta</th>\n","      <th>RecInd</th>\n","      <th>T_prec</th>\n","      <th>S_prec</th>\n","      <th>NH3q</th>\n","      <th>C14A1q</th>\n","      <th>C14A2q</th>\n","      <th>DarkAq</th>\n","      <th>MeanAq</th>\n","      <th>R_Depth</th>\n","      <th>R_TEMP</th>\n","      <th>R_POTEMP</th>\n","      <th>R_SALINITY</th>\n","      <th>R_SIGMA</th>\n","      <th>R_SVA</th>\n","      <th>R_DYNHT</th>\n","      <th>R_PRES</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>10.50</td>\n","      <td>33.440</td>\n","      <td>25.649</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>10.50</td>\n","      <td>10.50</td>\n","      <td>33.440</td>\n","      <td>25.64</td>\n","      <td>233.0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>10.46</td>\n","      <td>33.440</td>\n","      <td>25.656</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>8.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.440</td>\n","      <td>25.65</td>\n","      <td>232.5</td>\n","      <td>0.01</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>10.46</td>\n","      <td>33.437</td>\n","      <td>25.654</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>10.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.437</td>\n","      <td>25.65</td>\n","      <td>232.8</td>\n","      <td>0.02</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>10.45</td>\n","      <td>33.420</td>\n","      <td>25.643</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>19.0</td>\n","      <td>10.45</td>\n","      <td>10.45</td>\n","      <td>33.420</td>\n","      <td>25.64</td>\n","      <td>234.1</td>\n","      <td>0.04</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>20</td>\n","      <td>10.45</td>\n","      <td>33.421</td>\n","      <td>25.643</td>\n","      <td>7</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>20.0</td>\n","      <td>10.45</td>\n","      <td>10.45</td>\n","      <td>33.421</td>\n","      <td>25.64</td>\n","      <td>234.0</td>\n","      <td>0.04</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Cst_Cnt  Btl_Cnt  Depthm  T_degC  Salnty  STheta  RecInd  T_prec  S_prec  \\\n","0        1        1       0   10.50  33.440  25.649       3     1.0     2.0   \n","1        1        2       8   10.46  33.440  25.656       3     2.0     2.0   \n","2        1        3      10   10.46  33.437  25.654       7     2.0     3.0   \n","3        1        4      19   10.45  33.420  25.643       3     2.0     2.0   \n","4        1        5      20   10.45  33.421  25.643       7     2.0     3.0   \n","\n","   NH3q  C14A1q  C14A2q  DarkAq  MeanAq  R_Depth  R_TEMP  R_POTEMP  \\\n","0   9.0     9.0     9.0     9.0     9.0      0.0   10.50     10.50   \n","1   9.0     9.0     9.0     9.0     9.0      8.0   10.46     10.46   \n","2   9.0     9.0     9.0     9.0     9.0     10.0   10.46     10.46   \n","3   9.0     9.0     9.0     9.0     9.0     19.0   10.45     10.45   \n","4   9.0     9.0     9.0     9.0     9.0     20.0   10.45     10.45   \n","\n","   R_SALINITY  R_SIGMA  R_SVA  R_DYNHT  R_PRES  \n","0      33.440    25.64  233.0     0.00       0  \n","1      33.440    25.65  232.5     0.01       8  \n","2      33.437    25.65  232.8     0.02      10  \n","3      33.420    25.64  234.1     0.04      19  \n","4      33.421    25.64  234.0     0.04      20  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Inspecting Stats of the Numerical Features"]},{"cell_type":"markdown","metadata":{},"source":["We're gonna check out the std and scale of our data which we'll feed into our model. We'll want to make sure all of our data is on the same scale so certain columns aren't given more importance just because the rows have numbers on a bigger scale."]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.860369Z","iopub.status.busy":"2024-06-17T18:23:38.860073Z","iopub.status.idle":"2024-06-17T18:23:38.995166Z","shell.execute_reply":"2024-06-17T18:23:38.994056Z","shell.execute_reply.started":"2024-06-17T18:23:38.860343Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cst_Cnt</th>\n","      <th>Btl_Cnt</th>\n","      <th>Depthm</th>\n","      <th>RecInd</th>\n","      <th>R_PRES</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>733418.000000</td>\n","      <td>733418.000000</td>\n","      <td>733418.000000</td>\n","      <td>733418.000000</td>\n","      <td>733418.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>16421.194724</td>\n","      <td>414217.185100</td>\n","      <td>228.062580</td>\n","      <td>4.723822</td>\n","      <td>229.580553</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9482.694845</td>\n","      <td>230069.296792</td>\n","      <td>309.103372</td>\n","      <td>1.865705</td>\n","      <td>312.359267</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>8492.000000</td>\n","      <td>222666.250000</td>\n","      <td>50.000000</td>\n","      <td>3.000000</td>\n","      <td>50.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>15633.000000</td>\n","      <td>412554.500000</td>\n","      <td>125.000000</td>\n","      <td>3.000000</td>\n","      <td>126.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>24876.000000</td>\n","      <td>608509.750000</td>\n","      <td>300.000000</td>\n","      <td>7.000000</td>\n","      <td>302.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>34404.000000</td>\n","      <td>864861.000000</td>\n","      <td>5351.000000</td>\n","      <td>7.000000</td>\n","      <td>5458.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Cst_Cnt        Btl_Cnt         Depthm         RecInd  \\\n","count  733418.000000  733418.000000  733418.000000  733418.000000   \n","mean    16421.194724  414217.185100     228.062580       4.723822   \n","std      9482.694845  230069.296792     309.103372       1.865705   \n","min         1.000000       1.000000       0.000000       3.000000   \n","25%      8492.000000  222666.250000      50.000000       3.000000   \n","50%     15633.000000  412554.500000     125.000000       3.000000   \n","75%     24876.000000  608509.750000     300.000000       7.000000   \n","max     34404.000000  864861.000000    5351.000000       7.000000   \n","\n","              R_PRES  \n","count  733418.000000  \n","mean      229.580553  \n","std       312.359267  \n","min         0.000000  \n","25%        50.000000  \n","50%       126.000000  \n","75%       302.000000  \n","max      5458.000000  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# splitting columns up\n","\n","\n","# selecting Integer datatypes columns\n","df_int = df.select_dtypes(include=[\"int64\"])\n","# selecting float datatypes columns\n","df_float = df.select_dtypes(include=[\"float64\"])\n","\n","# checking out the stats\n","df_int.describe()"]},{"cell_type":"markdown","metadata":{},"source":["### Inspecting RecInd Column"]},{"cell_type":"markdown","metadata":{},"source":["Here we see that all of our columns look like continous values except 'RecInd', where it looks like a categorical column was encoded."]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:38.997339Z","iopub.status.busy":"2024-06-17T18:23:38.996891Z","iopub.status.idle":"2024-06-17T18:23:39.015014Z","shell.execute_reply":"2024-06-17T18:23:39.013922Z","shell.execute_reply.started":"2024-06-17T18:23:38.997299Z"},"trusted":true},"outputs":[{"data":{"text/plain":["RecInd\n","3    376861\n","7    275121\n","5     80506\n","6       928\n","4         2\n","Name: count, dtype: int64"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# let's check out the values of that column\n","df_int['RecInd'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["Instead of starting at 3, we're going to map it such that it starts at 0 and goes to 4. So 'scaling' our data. Unfortunately no meta data was provided for the dataset, so I'm not the most sure what this represents."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:39.016783Z","iopub.status.busy":"2024-06-17T18:23:39.016420Z","iopub.status.idle":"2024-06-17T18:23:39.105994Z","shell.execute_reply":"2024-06-17T18:23:39.104885Z","shell.execute_reply.started":"2024-06-17T18:23:39.016755Z"},"trusted":true},"outputs":[],"source":["# mapping_dict = {3:0,\n","#                 4:1,\n","#                 5:2,\n","#                 6:3,\n","#                 7:4\n","#                }\n","# df['RecInd'] = df['RecInd'].map(mapping_dict)\n","# df['RecInd'].head()\n","df = pd.get_dummies(df, columns=[\"RecInd\"],dtype=float)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:39.107527Z","iopub.status.busy":"2024-06-17T18:23:39.107215Z","iopub.status.idle":"2024-06-17T18:23:39.132295Z","shell.execute_reply":"2024-06-17T18:23:39.131211Z","shell.execute_reply.started":"2024-06-17T18:23:39.107500Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cst_Cnt</th>\n","      <th>Btl_Cnt</th>\n","      <th>Depthm</th>\n","      <th>T_degC</th>\n","      <th>Salnty</th>\n","      <th>STheta</th>\n","      <th>T_prec</th>\n","      <th>S_prec</th>\n","      <th>NH3q</th>\n","      <th>C14A1q</th>\n","      <th>C14A2q</th>\n","      <th>DarkAq</th>\n","      <th>MeanAq</th>\n","      <th>R_Depth</th>\n","      <th>R_TEMP</th>\n","      <th>R_POTEMP</th>\n","      <th>R_SALINITY</th>\n","      <th>R_SIGMA</th>\n","      <th>R_SVA</th>\n","      <th>R_DYNHT</th>\n","      <th>R_PRES</th>\n","      <th>RecInd_3</th>\n","      <th>RecInd_4</th>\n","      <th>RecInd_5</th>\n","      <th>RecInd_6</th>\n","      <th>RecInd_7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>10.50</td>\n","      <td>33.44</td>\n","      <td>25.649</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>10.50</td>\n","      <td>10.50</td>\n","      <td>33.44</td>\n","      <td>25.64</td>\n","      <td>233.0</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>10.46</td>\n","      <td>33.44</td>\n","      <td>25.656</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>8.0</td>\n","      <td>10.46</td>\n","      <td>10.46</td>\n","      <td>33.44</td>\n","      <td>25.65</td>\n","      <td>232.5</td>\n","      <td>0.01</td>\n","      <td>8</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Cst_Cnt  Btl_Cnt  Depthm  T_degC  Salnty  STheta  T_prec  S_prec  NH3q  \\\n","0        1        1       0   10.50   33.44  25.649     1.0     2.0   9.0   \n","1        1        2       8   10.46   33.44  25.656     2.0     2.0   9.0   \n","\n","   C14A1q  C14A2q  DarkAq  MeanAq  R_Depth  R_TEMP  R_POTEMP  R_SALINITY  \\\n","0     9.0     9.0     9.0     9.0      0.0   10.50     10.50       33.44   \n","1     9.0     9.0     9.0     9.0      8.0   10.46     10.46       33.44   \n","\n","   R_SIGMA  R_SVA  R_DYNHT  R_PRES  RecInd_3  RecInd_4  RecInd_5  RecInd_6  \\\n","0    25.64  233.0     0.00       0       1.0       0.0       0.0       0.0   \n","1    25.65  232.5     0.01       8       1.0       0.0       0.0       0.0   \n","\n","   RecInd_7  \n","0       0.0  \n","1       0.0  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df.head(2)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:39.134164Z","iopub.status.busy":"2024-06-17T18:23:39.133828Z","iopub.status.idle":"2024-06-17T18:23:39.213678Z","shell.execute_reply":"2024-06-17T18:23:39.212403Z","shell.execute_reply.started":"2024-06-17T18:23:39.134137Z"},"trusted":true},"outputs":[],"source":["# now lets use log function on our numerical features\n","log_int_cols = [col for col in df_int.columns if col != \"RecInd\"]\n","for col in log_int_cols:\n","    df[col] = np.log1p(df[col])\n","df[\"R_Depth\"] = np.log1p(df[\"R_Depth\"])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Preparing for Training"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:39.215444Z","iopub.status.busy":"2024-06-17T18:23:39.215096Z","iopub.status.idle":"2024-06-17T18:23:39.309018Z","shell.execute_reply":"2024-06-17T18:23:39.307855Z","shell.execute_reply.started":"2024-06-17T18:23:39.215415Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# splitting data into features and target values\n","X = df.drop(columns=['T_degC']).values\n","y = df['T_degC'].values"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:23:39.310562Z","iopub.status.busy":"2024-06-17T18:23:39.310244Z","iopub.status.idle":"2024-06-17T18:23:39.616705Z","shell.execute_reply":"2024-06-17T18:23:39.615727Z","shell.execute_reply.started":"2024-06-17T18:23:39.310535Z"},"trusted":true},"outputs":[],"source":["# Split data into training and validation features\n","X_train, X_val, t_train, t_val = train_test_split(X, y, test_size=0.1, random_state=17)"]},{"cell_type":"markdown","metadata":{},"source":["## Importance Normalization, and Standardization in Linear Regression\n","\n","\n","### Normalization\n","Normalization is the process of scaling data to fit within a specific range, typically [0, 1]. This is crucial for linear regression because it ensures that all features contribute equally to the model. Without normalization, features with larger ranges could dominate the regression model and skew the results. Min-max scaling is a common normalization technique.\n","\n","### Standardization\n","Standardization scales data to have a mean of 0 and a standard deviation of 1. This process is essential for linear regression because it ensures that the model's weights are on a comparable scale, which can lead to more stable and faster convergence during training. Standardization is typically performed using z-score scaling."]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:31.102285Z","iopub.status.busy":"2024-06-17T18:25:31.101341Z","iopub.status.idle":"2024-06-17T18:25:31.249472Z","shell.execute_reply":"2024-06-17T18:25:31.248368Z","shell.execute_reply.started":"2024-06-17T18:25:31.102245Z"},"trusted":true},"outputs":[],"source":["numerical_columns = df.select_dtypes(include=[np.number]).columns"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:32.256963Z","iopub.status.busy":"2024-06-17T18:25:32.256547Z","iopub.status.idle":"2024-06-17T18:25:32.469916Z","shell.execute_reply":"2024-06-17T18:25:32.468805Z","shell.execute_reply.started":"2024-06-17T18:25:32.256928Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Numerical variables normalized.\n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Normalizing numerical variables\n","def normalize_transform(X_train, X_val):\n","    scaler = MinMaxScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_val_scaled = scaler.transform(X_val)\n","\n","    return X_train_scaled, X_val_scaled\n","\n","print(\"Numerical variables normalized.\")\n","X_train, X_val = normalize_transform(X_train, X_val)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:34.422686Z","iopub.status.busy":"2024-06-17T18:25:34.421420Z","iopub.status.idle":"2024-06-17T18:25:34.764909Z","shell.execute_reply":"2024-06-17T18:25:34.763676Z","shell.execute_reply.started":"2024-06-17T18:25:34.422635Z"},"trusted":true},"outputs":[],"source":["# let's also standardize our data while we're at it\n","from sklearn.preprocessing import StandardScaler\n","\n","# Initialize the scaler\n","scaler = StandardScaler()\n","\n","# Fit the scaler on the training data and transform the training data\n","X_train = scaler.fit_transform(X_train)\n","\n","# Use the same scaler to transform the test data\n","X_val = scaler.transform(X_val)\n"]},{"cell_type":"markdown","metadata":{},"source":["Converting our training and validation data to pytorch tensors"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:36.594808Z","iopub.status.busy":"2024-06-17T18:25:36.594328Z","iopub.status.idle":"2024-06-17T18:25:39.429858Z","shell.execute_reply":"2024-06-17T18:25:39.428800Z","shell.execute_reply.started":"2024-06-17T18:25:36.594770Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","# Convert to PyTorch tensors\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","t_train = torch.tensor(t_train, dtype=torch.float32).view(-1, 1)\n","X_val = torch.tensor(X_val, dtype=torch.float32)\n","t_val = torch.tensor(t_val, dtype=torch.float32).view(-1, 1)"]},{"cell_type":"markdown","metadata":{},"source":["# Defining Our Model"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:39.433405Z","iopub.status.busy":"2024-06-17T18:25:39.432109Z","iopub.status.idle":"2024-06-17T18:25:40.729144Z","shell.execute_reply":"2024-06-17T18:25:40.728006Z","shell.execute_reply.started":"2024-06-17T18:25:39.433357Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","class TwoLayerRegressionModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim):\n","        super(TwoLayerRegressionModel, self).__init__()\n","        self.hidden = nn.Linear(input_dim, hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.output = nn.Linear(hidden_dim, 1)\n","    \n","    def forward(self, x):\n","        x = self.hidden(x)\n","        x = self.relu(x)\n","        x = self.output(x)\n","        return x\n","\n","# 25 input dim in our training set\n","input_dim = 25\n","hidden_dim = 10\n","model = TwoLayerRegressionModel(input_dim, hidden_dim)\n","\n","\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training Loop"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:40.730901Z","iopub.status.busy":"2024-06-17T18:25:40.730378Z","iopub.status.idle":"2024-06-17T18:25:52.363555Z","shell.execute_reply":"2024-06-17T18:25:52.362408Z","shell.execute_reply.started":"2024-06-17T18:25:40.730868Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [10/200], Loss: 28.4063\n","Epoch [20/200], Loss: 12.8444\n","Epoch [30/200], Loss: 5.7659\n","Epoch [40/200], Loss: 2.1046\n","Epoch [50/200], Loss: 0.8519\n","Epoch [60/200], Loss: 0.5351\n","Epoch [70/200], Loss: 0.4217\n","Epoch [80/200], Loss: 0.3593\n","Epoch [90/200], Loss: 0.3154\n","Epoch [100/200], Loss: 0.2804\n","Epoch [110/200], Loss: 0.2511\n","Epoch [120/200], Loss: 0.2263\n","Epoch [130/200], Loss: 0.2052\n","Epoch [140/200], Loss: 0.1871\n","Epoch [150/200], Loss: 0.1718\n","Epoch [160/200], Loss: 0.1586\n","Epoch [170/200], Loss: 0.1473\n","Epoch [180/200], Loss: 0.1374\n","Epoch [190/200], Loss: 0.1287\n","Epoch [200/200], Loss: 0.1209\n"]}],"source":["# Training loop\n","num_epochs = 200\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    \n","    outputs = model(X_train)\n","    loss = criterion(outputs, t_train)\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (epoch+1) % 10 == 0:\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluting Model"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:52.366995Z","iopub.status.busy":"2024-06-17T18:25:52.366366Z","iopub.status.idle":"2024-06-17T18:25:52.375107Z","shell.execute_reply":"2024-06-17T18:25:52.374044Z","shell.execute_reply.started":"2024-06-17T18:25:52.366949Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 0.1192\n"]}],"source":["# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    predictions = model(X_val)\n","    test_loss = criterion(predictions, t_val)\n","    print(f'Test Loss: {test_loss.item():.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["Our training loss was always lower than our testing loss so it means our model wasn't over fitting yet and that we could continue to train it to squeeze even more preformance from it."]},{"cell_type":"markdown","metadata":{},"source":["## Storing the Model in the System"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:52.376863Z","iopub.status.busy":"2024-06-17T18:25:52.376435Z","iopub.status.idle":"2024-06-17T18:25:52.383951Z","shell.execute_reply":"2024-06-17T18:25:52.382938Z","shell.execute_reply.started":"2024-06-17T18:25:52.376833Z"},"trusted":true},"outputs":[],"source":["import pickle\n","\n","# save the model to disk\n","model_filename = \"model.pkl\"\n","pickle.dump(model, open(model_filename, \"wb\"))"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Model Back "]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:25:52.385461Z","iopub.status.busy":"2024-06-17T18:25:52.385141Z","iopub.status.idle":"2024-06-17T18:25:52.395907Z","shell.execute_reply":"2024-06-17T18:25:52.394733Z","shell.execute_reply.started":"2024-06-17T18:25:52.385429Z"},"trusted":true},"outputs":[],"source":["loaded_model = pickle.load(open(\"model.pkl\", \"rb\"))"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-06-17T18:26:58.848943Z","iopub.status.busy":"2024-06-17T18:26:58.848454Z","iopub.status.idle":"2024-06-17T18:26:58.857964Z","shell.execute_reply":"2024-06-17T18:26:58.856694Z","shell.execute_reply.started":"2024-06-17T18:26:58.848907Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["True value: tensor([5.3800])\n","Predicted value: tensor([5.2377])\n"]}],"source":["# doing an example prediction\n","\n","# switch to evaluation mode\n","model.eval()\n","\n","# Generate Predictions:\n","with torch.no_grad():\n","    prediction = model(X_val[2])\n","print(\"True value:\", t_val[2])\n","print(\"Predicted value:\", prediction)"]},{"cell_type":"markdown","metadata":{},"source":["# Next Steps to Improve Preformance!\n","- Increase training epochs to overfit model --> proves problem has a solution!\n","- Consider adding dropout layers to reel the model back in.\n","- Add in other columns with missing data to increase the amount of data the model has to look at\n","- Change model capacity and parameters!\n","- Fine tune model with Grid search or random search algorithms to find better hyperparameters.\n","- Try out other models ex: Scikit learn Linear Regression model"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2190,"sourceId":3685,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
