{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3685,"sourceType":"datasetVersion","datasetId":2190}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-17T18:23:31.560979Z","iopub.execute_input":"2024-06-17T18:23:31.561363Z","iopub.status.idle":"2024-06-17T18:23:31.570892Z","shell.execute_reply.started":"2024-06-17T18:23:31.561335Z","shell.execute_reply":"2024-06-17T18:23:31.569707Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/input/calcofi/bottle.csv\n/kaggle/input/calcofi/cast.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:31.572475Z","iopub.execute_input":"2024-06-17T18:23:31.572803Z","iopub.status.idle":"2024-06-17T18:23:31.604866Z","shell.execute_reply.started":"2024-06-17T18:23:31.572774Z","shell.execute_reply":"2024-06-17T18:23:31.603387Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/calcofi/bottle.csv')\npd.options.display.max_columns = None\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:31.606597Z","iopub.execute_input":"2024-06-17T18:23:31.607457Z","iopub.status.idle":"2024-06-17T18:23:37.729419Z","shell.execute_reply.started":"2024-06-17T18:23:31.607423Z","shell.execute_reply":"2024-06-17T18:23:37.728193Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2584783190.py:1: DtypeWarning: Columns (47,73) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('/kaggle/input/calcofi/bottle.csv')\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   Cst_Cnt  Btl_Cnt       Sta_ID                                Depth_ID  \\\n0        1        1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3   \n1        1        2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3   \n2        1        3  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7   \n3        1        4  054.0 056.0  19-4903CR-HY-060-0930-05400560-0019A-3   \n4        1        5  054.0 056.0  19-4903CR-HY-060-0930-05400560-0020A-7   \n\n   Depthm  T_degC  Salnty  O2ml_L  STheta  O2Sat  Oxy_µmol/Kg  BtlNum  RecInd  \\\n0       0   10.50  33.440     NaN  25.649    NaN          NaN     NaN       3   \n1       8   10.46  33.440     NaN  25.656    NaN          NaN     NaN       3   \n2      10   10.46  33.437     NaN  25.654    NaN          NaN     NaN       7   \n3      19   10.45  33.420     NaN  25.643    NaN          NaN     NaN       3   \n4      20   10.45  33.421     NaN  25.643    NaN          NaN     NaN       7   \n\n   T_prec  T_qual  S_prec  S_qual  P_qual  O_qual  SThtaq  O2Satq  ChlorA  \\\n0     1.0     NaN     2.0     NaN     9.0     9.0     NaN     9.0     NaN   \n1     2.0     NaN     2.0     NaN     9.0     9.0     NaN     9.0     NaN   \n2     2.0     NaN     3.0     NaN     9.0     9.0     NaN     9.0     NaN   \n3     2.0     NaN     2.0     NaN     9.0     9.0     NaN     9.0     NaN   \n4     2.0     NaN     3.0     NaN     9.0     9.0     NaN     9.0     NaN   \n\n   Chlqua  Phaeop  Phaqua  PO4uM  PO4q  SiO3uM  SiO3qu  NO2uM  NO2q  NO3uM  \\\n0     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n1     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n2     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n3     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n4     9.0     NaN     9.0    NaN   9.0     NaN     9.0    NaN   9.0    NaN   \n\n   NO3q  NH3uM  NH3q  C14As1  C14A1p  C14A1q  C14As2  C14A2p  C14A2q  DarkAs  \\\n0   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n1   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n2   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n3   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n4   9.0    NaN   9.0     NaN     NaN     9.0     NaN     NaN     9.0     NaN   \n\n   DarkAp  DarkAq  MeanAs  MeanAp  MeanAq IncTim  LightP  R_Depth  R_TEMP  \\\n0     NaN     9.0     NaN     NaN     9.0    NaN     NaN      0.0   10.50   \n1     NaN     9.0     NaN     NaN     9.0    NaN     NaN      8.0   10.46   \n2     NaN     9.0     NaN     NaN     9.0    NaN     NaN     10.0   10.46   \n3     NaN     9.0     NaN     NaN     9.0    NaN     NaN     19.0   10.45   \n4     NaN     9.0     NaN     NaN     9.0    NaN     NaN     20.0   10.45   \n\n   R_POTEMP  R_SALINITY  R_SIGMA  R_SVA  R_DYNHT  R_O2  R_O2Sat  R_SIO3  \\\n0     10.50      33.440    25.64  233.0     0.00   NaN      NaN     NaN   \n1     10.46      33.440    25.65  232.5     0.01   NaN      NaN     NaN   \n2     10.46      33.437    25.65  232.8     0.02   NaN      NaN     NaN   \n3     10.45      33.420    25.64  234.1     0.04   NaN      NaN     NaN   \n4     10.45      33.421    25.64  234.0     0.04   NaN      NaN     NaN   \n\n   R_PO4  R_NO3  R_NO2  R_NH4  R_CHLA  R_PHAEO  R_PRES  R_SAMP  DIC1  DIC2  \\\n0    NaN    NaN    NaN    NaN     NaN      NaN       0     NaN   NaN   NaN   \n1    NaN    NaN    NaN    NaN     NaN      NaN       8     NaN   NaN   NaN   \n2    NaN    NaN    NaN    NaN     NaN      NaN      10     NaN   NaN   NaN   \n3    NaN    NaN    NaN    NaN     NaN      NaN      19     NaN   NaN   NaN   \n4    NaN    NaN    NaN    NaN     NaN      NaN      20     NaN   NaN   NaN   \n\n   TA1  TA2  pH2  pH1 DIC Quality Comment  \n0  NaN  NaN  NaN  NaN                 NaN  \n1  NaN  NaN  NaN  NaN                 NaN  \n2  NaN  NaN  NaN  NaN                 NaN  \n3  NaN  NaN  NaN  NaN                 NaN  \n4  NaN  NaN  NaN  NaN                 NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cst_Cnt</th>\n      <th>Btl_Cnt</th>\n      <th>Sta_ID</th>\n      <th>Depth_ID</th>\n      <th>Depthm</th>\n      <th>T_degC</th>\n      <th>Salnty</th>\n      <th>O2ml_L</th>\n      <th>STheta</th>\n      <th>O2Sat</th>\n      <th>Oxy_µmol/Kg</th>\n      <th>BtlNum</th>\n      <th>RecInd</th>\n      <th>T_prec</th>\n      <th>T_qual</th>\n      <th>S_prec</th>\n      <th>S_qual</th>\n      <th>P_qual</th>\n      <th>O_qual</th>\n      <th>SThtaq</th>\n      <th>O2Satq</th>\n      <th>ChlorA</th>\n      <th>Chlqua</th>\n      <th>Phaeop</th>\n      <th>Phaqua</th>\n      <th>PO4uM</th>\n      <th>PO4q</th>\n      <th>SiO3uM</th>\n      <th>SiO3qu</th>\n      <th>NO2uM</th>\n      <th>NO2q</th>\n      <th>NO3uM</th>\n      <th>NO3q</th>\n      <th>NH3uM</th>\n      <th>NH3q</th>\n      <th>C14As1</th>\n      <th>C14A1p</th>\n      <th>C14A1q</th>\n      <th>C14As2</th>\n      <th>C14A2p</th>\n      <th>C14A2q</th>\n      <th>DarkAs</th>\n      <th>DarkAp</th>\n      <th>DarkAq</th>\n      <th>MeanAs</th>\n      <th>MeanAp</th>\n      <th>MeanAq</th>\n      <th>IncTim</th>\n      <th>LightP</th>\n      <th>R_Depth</th>\n      <th>R_TEMP</th>\n      <th>R_POTEMP</th>\n      <th>R_SALINITY</th>\n      <th>R_SIGMA</th>\n      <th>R_SVA</th>\n      <th>R_DYNHT</th>\n      <th>R_O2</th>\n      <th>R_O2Sat</th>\n      <th>R_SIO3</th>\n      <th>R_PO4</th>\n      <th>R_NO3</th>\n      <th>R_NO2</th>\n      <th>R_NH4</th>\n      <th>R_CHLA</th>\n      <th>R_PHAEO</th>\n      <th>R_PRES</th>\n      <th>R_SAMP</th>\n      <th>DIC1</th>\n      <th>DIC2</th>\n      <th>TA1</th>\n      <th>TA2</th>\n      <th>pH2</th>\n      <th>pH1</th>\n      <th>DIC Quality Comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n      <td>0</td>\n      <td>10.50</td>\n      <td>33.440</td>\n      <td>NaN</td>\n      <td>25.649</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>10.50</td>\n      <td>10.50</td>\n      <td>33.440</td>\n      <td>25.64</td>\n      <td>233.0</td>\n      <td>0.00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n      <td>8</td>\n      <td>10.46</td>\n      <td>33.440</td>\n      <td>NaN</td>\n      <td>25.656</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.440</td>\n      <td>25.65</td>\n      <td>232.5</td>\n      <td>0.01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n      <td>10</td>\n      <td>10.46</td>\n      <td>33.437</td>\n      <td>NaN</td>\n      <td>25.654</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.437</td>\n      <td>25.65</td>\n      <td>232.8</td>\n      <td>0.02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0019A-3</td>\n      <td>19</td>\n      <td>10.45</td>\n      <td>33.420</td>\n      <td>NaN</td>\n      <td>25.643</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19.0</td>\n      <td>10.45</td>\n      <td>10.45</td>\n      <td>33.420</td>\n      <td>25.64</td>\n      <td>234.1</td>\n      <td>0.04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0020A-7</td>\n      <td>20</td>\n      <td>10.45</td>\n      <td>33.421</td>\n      <td>NaN</td>\n      <td>25.643</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>10.45</td>\n      <td>10.45</td>\n      <td>33.421</td>\n      <td>25.64</td>\n      <td>234.0</td>\n      <td>0.04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# 74 columns, 864,863 rows\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:37.731745Z","iopub.execute_input":"2024-06-17T18:23:37.732179Z","iopub.status.idle":"2024-06-17T18:23:37.739163Z","shell.execute_reply.started":"2024-06-17T18:23:37.732140Z","shell.execute_reply":"2024-06-17T18:23:37.738060Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(864863, 74)"},"metadata":{}}]},{"cell_type":"code","source":"# how many null values are in our dataset?\ndf.isna().sum() ","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:37.740492Z","iopub.execute_input":"2024-06-17T18:23:37.740856Z","iopub.status.idle":"2024-06-17T18:23:37.962029Z","shell.execute_reply.started":"2024-06-17T18:23:37.740827Z","shell.execute_reply":"2024-06-17T18:23:37.961012Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Cst_Cnt                     0\nBtl_Cnt                     0\nSta_ID                      0\nDepth_ID                    0\nDepthm                      0\n                        ...  \nTA1                    862779\nTA2                    864629\npH2                    864853\npH1                    864779\nDIC Quality Comment    864808\nLength: 74, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"We see that our data has many columns with substantial amounts of missing values. Let's stick with columns that have fewer than 10% missing data since we have a large number of columns.","metadata":{}},{"cell_type":"code","source":"columns = [col for col in df.columns if (df[col].isnull().sum() / df.shape[0]) <= 0.07]\ncolumns, len(columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:37.964650Z","iopub.execute_input":"2024-06-17T18:23:37.965080Z","iopub.status.idle":"2024-06-17T18:23:38.188977Z","shell.execute_reply.started":"2024-06-17T18:23:37.965043Z","shell.execute_reply":"2024-06-17T18:23:38.187963Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(['Cst_Cnt',\n  'Btl_Cnt',\n  'Sta_ID',\n  'Depth_ID',\n  'Depthm',\n  'T_degC',\n  'Salnty',\n  'STheta',\n  'RecInd',\n  'T_prec',\n  'S_prec',\n  'NH3q',\n  'C14A1q',\n  'C14A2q',\n  'DarkAq',\n  'MeanAq',\n  'R_Depth',\n  'R_TEMP',\n  'R_POTEMP',\n  'R_SALINITY',\n  'R_SIGMA',\n  'R_SVA',\n  'R_DYNHT',\n  'R_PRES'],\n 24)"},"metadata":{}}]},{"cell_type":"markdown","source":"We're left with 24 columns out of the 74. For our first pass and to make it simple, we're going to drop the 50 columns that have high amounts of na values. This will give us a quick and easy baseline. If our model preformance is good, we don't need to add in more columns, however, if it's bad we can consider doing more data processing.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#  getting rid of the 50 columns\ndf = df[columns]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.190236Z","iopub.execute_input":"2024-06-17T18:23:38.190640Z","iopub.status.idle":"2024-06-17T18:23:38.264593Z","shell.execute_reply.started":"2024-06-17T18:23:38.190605Z","shell.execute_reply":"2024-06-17T18:23:38.263479Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   Cst_Cnt  Btl_Cnt       Sta_ID                                Depth_ID  \\\n0        1        1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3   \n1        1        2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3   \n2        1        3  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7   \n3        1        4  054.0 056.0  19-4903CR-HY-060-0930-05400560-0019A-3   \n4        1        5  054.0 056.0  19-4903CR-HY-060-0930-05400560-0020A-7   \n\n   Depthm  T_degC  Salnty  STheta  RecInd  T_prec  S_prec  NH3q  C14A1q  \\\n0       0   10.50  33.440  25.649       3     1.0     2.0   9.0     9.0   \n1       8   10.46  33.440  25.656       3     2.0     2.0   9.0     9.0   \n2      10   10.46  33.437  25.654       7     2.0     3.0   9.0     9.0   \n3      19   10.45  33.420  25.643       3     2.0     2.0   9.0     9.0   \n4      20   10.45  33.421  25.643       7     2.0     3.0   9.0     9.0   \n\n   C14A2q  DarkAq  MeanAq  R_Depth  R_TEMP  R_POTEMP  R_SALINITY  R_SIGMA  \\\n0     9.0     9.0     9.0      0.0   10.50     10.50      33.440    25.64   \n1     9.0     9.0     9.0      8.0   10.46     10.46      33.440    25.65   \n2     9.0     9.0     9.0     10.0   10.46     10.46      33.437    25.65   \n3     9.0     9.0     9.0     19.0   10.45     10.45      33.420    25.64   \n4     9.0     9.0     9.0     20.0   10.45     10.45      33.421    25.64   \n\n   R_SVA  R_DYNHT  R_PRES  \n0  233.0     0.00       0  \n1  232.5     0.01       8  \n2  232.8     0.02      10  \n3  234.1     0.04      19  \n4  234.0     0.04      20  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cst_Cnt</th>\n      <th>Btl_Cnt</th>\n      <th>Sta_ID</th>\n      <th>Depth_ID</th>\n      <th>Depthm</th>\n      <th>T_degC</th>\n      <th>Salnty</th>\n      <th>STheta</th>\n      <th>RecInd</th>\n      <th>T_prec</th>\n      <th>S_prec</th>\n      <th>NH3q</th>\n      <th>C14A1q</th>\n      <th>C14A2q</th>\n      <th>DarkAq</th>\n      <th>MeanAq</th>\n      <th>R_Depth</th>\n      <th>R_TEMP</th>\n      <th>R_POTEMP</th>\n      <th>R_SALINITY</th>\n      <th>R_SIGMA</th>\n      <th>R_SVA</th>\n      <th>R_DYNHT</th>\n      <th>R_PRES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n      <td>0</td>\n      <td>10.50</td>\n      <td>33.440</td>\n      <td>25.649</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>10.50</td>\n      <td>10.50</td>\n      <td>33.440</td>\n      <td>25.64</td>\n      <td>233.0</td>\n      <td>0.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n      <td>8</td>\n      <td>10.46</td>\n      <td>33.440</td>\n      <td>25.656</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.440</td>\n      <td>25.65</td>\n      <td>232.5</td>\n      <td>0.01</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n      <td>10</td>\n      <td>10.46</td>\n      <td>33.437</td>\n      <td>25.654</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.437</td>\n      <td>25.65</td>\n      <td>232.8</td>\n      <td>0.02</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0019A-3</td>\n      <td>19</td>\n      <td>10.45</td>\n      <td>33.420</td>\n      <td>25.643</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>19.0</td>\n      <td>10.45</td>\n      <td>10.45</td>\n      <td>33.420</td>\n      <td>25.64</td>\n      <td>234.1</td>\n      <td>0.04</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0020A-7</td>\n      <td>20</td>\n      <td>10.45</td>\n      <td>33.421</td>\n      <td>25.643</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>10.45</td>\n      <td>10.45</td>\n      <td>33.421</td>\n      <td>25.64</td>\n      <td>234.0</td>\n      <td>0.04</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# checking null values again\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.266781Z","iopub.execute_input":"2024-06-17T18:23:38.267240Z","iopub.status.idle":"2024-06-17T18:23:38.382178Z","shell.execute_reply.started":"2024-06-17T18:23:38.267201Z","shell.execute_reply":"2024-06-17T18:23:38.381093Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Cst_Cnt           0\nBtl_Cnt           0\nSta_ID            0\nDepth_ID          0\nDepthm            0\nT_degC        10963\nSalnty        47354\nSTheta        52689\nRecInd            0\nT_prec        10963\nS_prec        47354\nNH3q          56564\nC14A1q        16258\nC14A2q        16240\nDarkAq        24423\nMeanAq        24424\nR_Depth           0\nR_TEMP        10963\nR_POTEMP      46047\nR_SALINITY    47354\nR_SIGMA       52856\nR_SVA         52771\nR_DYNHT       46657\nR_PRES            0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"We have a large amount of data so we're going to take a quick approach and simply drop the ropws with missing data. This isn't ideal, but for a first iteration of our model, it's a good way to get a baseline. From eariler, we know that none of the columns have no more than 10% missing data, so dropping the rows with missing data should still keep most of the data and preserve the columns.","metadata":{}},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.383624Z","iopub.execute_input":"2024-06-17T18:23:38.383974Z","iopub.status.idle":"2024-06-17T18:23:38.545326Z","shell.execute_reply.started":"2024-06-17T18:23:38.383945Z","shell.execute_reply":"2024-06-17T18:23:38.544211Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# checking null values again\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.546629Z","iopub.execute_input":"2024-06-17T18:23:38.546954Z","iopub.status.idle":"2024-06-17T18:23:38.646270Z","shell.execute_reply.started":"2024-06-17T18:23:38.546927Z","shell.execute_reply":"2024-06-17T18:23:38.645074Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Cst_Cnt       0\nBtl_Cnt       0\nSta_ID        0\nDepth_ID      0\nDepthm        0\nT_degC        0\nSalnty        0\nSTheta        0\nRecInd        0\nT_prec        0\nS_prec        0\nNH3q          0\nC14A1q        0\nC14A2q        0\nDarkAq        0\nMeanAq        0\nR_Depth       0\nR_TEMP        0\nR_POTEMP      0\nR_SALINITY    0\nR_SIGMA       0\nR_SVA         0\nR_DYNHT       0\nR_PRES        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Ahh, beautiful, no missing data!","metadata":{}},{"cell_type":"markdown","source":"### Inspecting Column Data Types","metadata":{}},{"cell_type":"code","source":"# we're looking for non continuous values --> \"string\" values\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.647893Z","iopub.execute_input":"2024-06-17T18:23:38.648227Z","iopub.status.idle":"2024-06-17T18:23:38.762219Z","shell.execute_reply.started":"2024-06-17T18:23:38.648201Z","shell.execute_reply":"2024-06-17T18:23:38.760872Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 733418 entries, 0 to 864860\nData columns (total 24 columns):\n #   Column      Non-Null Count   Dtype  \n---  ------      --------------   -----  \n 0   Cst_Cnt     733418 non-null  int64  \n 1   Btl_Cnt     733418 non-null  int64  \n 2   Sta_ID      733418 non-null  object \n 3   Depth_ID    733418 non-null  object \n 4   Depthm      733418 non-null  int64  \n 5   T_degC      733418 non-null  float64\n 6   Salnty      733418 non-null  float64\n 7   STheta      733418 non-null  float64\n 8   RecInd      733418 non-null  int64  \n 9   T_prec      733418 non-null  float64\n 10  S_prec      733418 non-null  float64\n 11  NH3q        733418 non-null  float64\n 12  C14A1q      733418 non-null  float64\n 13  C14A2q      733418 non-null  float64\n 14  DarkAq      733418 non-null  float64\n 15  MeanAq      733418 non-null  float64\n 16  R_Depth     733418 non-null  float64\n 17  R_TEMP      733418 non-null  float64\n 18  R_POTEMP    733418 non-null  float64\n 19  R_SALINITY  733418 non-null  float64\n 20  R_SIGMA     733418 non-null  float64\n 21  R_SVA       733418 non-null  float64\n 22  R_DYNHT     733418 non-null  float64\n 23  R_PRES      733418 non-null  int64  \ndtypes: float64(17), int64(5), object(2)\nmemory usage: 139.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.select_dtypes('object').head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.765690Z","iopub.execute_input":"2024-06-17T18:23:38.766059Z","iopub.status.idle":"2024-06-17T18:23:38.790926Z","shell.execute_reply.started":"2024-06-17T18:23:38.766029Z","shell.execute_reply":"2024-06-17T18:23:38.789565Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"        Sta_ID                                Depth_ID\n0  054.0 056.0  19-4903CR-HY-060-0930-05400560-0000A-3\n1  054.0 056.0  19-4903CR-HY-060-0930-05400560-0008A-3\n2  054.0 056.0  19-4903CR-HY-060-0930-05400560-0010A-7","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sta_ID</th>\n      <th>Depth_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0000A-3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0008A-3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>054.0 056.0</td>\n      <td>19-4903CR-HY-060-0930-05400560-0010A-7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Since these columns appear to just be ID columns and not very informative, we are going to drop them. If our model preformance is poor, we can look to add them back in.","metadata":{}},{"cell_type":"code","source":"df.drop(['Sta_ID','Depth_ID'], inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.792192Z","iopub.execute_input":"2024-06-17T18:23:38.792608Z","iopub.status.idle":"2024-06-17T18:23:38.831082Z","shell.execute_reply.started":"2024-06-17T18:23:38.792551Z","shell.execute_reply":"2024-06-17T18:23:38.829942Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.832771Z","iopub.execute_input":"2024-06-17T18:23:38.833153Z","iopub.status.idle":"2024-06-17T18:23:38.858889Z","shell.execute_reply.started":"2024-06-17T18:23:38.833122Z","shell.execute_reply":"2024-06-17T18:23:38.857794Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   Cst_Cnt  Btl_Cnt  Depthm  T_degC  Salnty  STheta  RecInd  T_prec  S_prec  \\\n0        1        1       0   10.50  33.440  25.649       3     1.0     2.0   \n1        1        2       8   10.46  33.440  25.656       3     2.0     2.0   \n2        1        3      10   10.46  33.437  25.654       7     2.0     3.0   \n3        1        4      19   10.45  33.420  25.643       3     2.0     2.0   \n4        1        5      20   10.45  33.421  25.643       7     2.0     3.0   \n\n   NH3q  C14A1q  C14A2q  DarkAq  MeanAq  R_Depth  R_TEMP  R_POTEMP  \\\n0   9.0     9.0     9.0     9.0     9.0      0.0   10.50     10.50   \n1   9.0     9.0     9.0     9.0     9.0      8.0   10.46     10.46   \n2   9.0     9.0     9.0     9.0     9.0     10.0   10.46     10.46   \n3   9.0     9.0     9.0     9.0     9.0     19.0   10.45     10.45   \n4   9.0     9.0     9.0     9.0     9.0     20.0   10.45     10.45   \n\n   R_SALINITY  R_SIGMA  R_SVA  R_DYNHT  R_PRES  \n0      33.440    25.64  233.0     0.00       0  \n1      33.440    25.65  232.5     0.01       8  \n2      33.437    25.65  232.8     0.02      10  \n3      33.420    25.64  234.1     0.04      19  \n4      33.421    25.64  234.0     0.04      20  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cst_Cnt</th>\n      <th>Btl_Cnt</th>\n      <th>Depthm</th>\n      <th>T_degC</th>\n      <th>Salnty</th>\n      <th>STheta</th>\n      <th>RecInd</th>\n      <th>T_prec</th>\n      <th>S_prec</th>\n      <th>NH3q</th>\n      <th>C14A1q</th>\n      <th>C14A2q</th>\n      <th>DarkAq</th>\n      <th>MeanAq</th>\n      <th>R_Depth</th>\n      <th>R_TEMP</th>\n      <th>R_POTEMP</th>\n      <th>R_SALINITY</th>\n      <th>R_SIGMA</th>\n      <th>R_SVA</th>\n      <th>R_DYNHT</th>\n      <th>R_PRES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.50</td>\n      <td>33.440</td>\n      <td>25.649</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>10.50</td>\n      <td>10.50</td>\n      <td>33.440</td>\n      <td>25.64</td>\n      <td>233.0</td>\n      <td>0.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>10.46</td>\n      <td>33.440</td>\n      <td>25.656</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.440</td>\n      <td>25.65</td>\n      <td>232.5</td>\n      <td>0.01</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>10.46</td>\n      <td>33.437</td>\n      <td>25.654</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.437</td>\n      <td>25.65</td>\n      <td>232.8</td>\n      <td>0.02</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>19</td>\n      <td>10.45</td>\n      <td>33.420</td>\n      <td>25.643</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>19.0</td>\n      <td>10.45</td>\n      <td>10.45</td>\n      <td>33.420</td>\n      <td>25.64</td>\n      <td>234.1</td>\n      <td>0.04</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>20</td>\n      <td>10.45</td>\n      <td>33.421</td>\n      <td>25.643</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>10.45</td>\n      <td>10.45</td>\n      <td>33.421</td>\n      <td>25.64</td>\n      <td>234.0</td>\n      <td>0.04</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inspecting Stats of the Numerical Features","metadata":{}},{"cell_type":"markdown","source":"We're gonna check out the std and scale of our data which we'll feed into our model. We'll want to make sure all of our data is on the same scale so certain columns aren't given more importance just because the rows have numbers on a bigger scale.","metadata":{}},{"cell_type":"code","source":"# splitting columns up\n\n\n# selecting Integer datatypes columns\ndf_int = df.select_dtypes(include=[\"int64\"])\n# selecting float datatypes columns\ndf_float = df.select_dtypes(include=[\"float64\"])\n\n# checking out the stats\ndf_int.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.860073Z","iopub.execute_input":"2024-06-17T18:23:38.860369Z","iopub.status.idle":"2024-06-17T18:23:38.995166Z","shell.execute_reply.started":"2024-06-17T18:23:38.860343Z","shell.execute_reply":"2024-06-17T18:23:38.994056Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"             Cst_Cnt        Btl_Cnt         Depthm         RecInd  \\\ncount  733418.000000  733418.000000  733418.000000  733418.000000   \nmean    16421.194724  414217.185100     228.062580       4.723822   \nstd      9482.694845  230069.296792     309.103372       1.865705   \nmin         1.000000       1.000000       0.000000       3.000000   \n25%      8492.000000  222666.250000      50.000000       3.000000   \n50%     15633.000000  412554.500000     125.000000       3.000000   \n75%     24876.000000  608509.750000     300.000000       7.000000   \nmax     34404.000000  864861.000000    5351.000000       7.000000   \n\n              R_PRES  \ncount  733418.000000  \nmean      229.580553  \nstd       312.359267  \nmin         0.000000  \n25%        50.000000  \n50%       126.000000  \n75%       302.000000  \nmax      5458.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cst_Cnt</th>\n      <th>Btl_Cnt</th>\n      <th>Depthm</th>\n      <th>RecInd</th>\n      <th>R_PRES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>733418.000000</td>\n      <td>733418.000000</td>\n      <td>733418.000000</td>\n      <td>733418.000000</td>\n      <td>733418.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>16421.194724</td>\n      <td>414217.185100</td>\n      <td>228.062580</td>\n      <td>4.723822</td>\n      <td>229.580553</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9482.694845</td>\n      <td>230069.296792</td>\n      <td>309.103372</td>\n      <td>1.865705</td>\n      <td>312.359267</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8492.000000</td>\n      <td>222666.250000</td>\n      <td>50.000000</td>\n      <td>3.000000</td>\n      <td>50.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>15633.000000</td>\n      <td>412554.500000</td>\n      <td>125.000000</td>\n      <td>3.000000</td>\n      <td>126.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>24876.000000</td>\n      <td>608509.750000</td>\n      <td>300.000000</td>\n      <td>7.000000</td>\n      <td>302.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>34404.000000</td>\n      <td>864861.000000</td>\n      <td>5351.000000</td>\n      <td>7.000000</td>\n      <td>5458.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Inspecting RecInd Column","metadata":{}},{"cell_type":"markdown","source":"Here we see that all of our columns look like continous values except 'RecInd', where it looks like a categorical column was encoded.","metadata":{}},{"cell_type":"code","source":"# let's check out the values of that column\ndf_int['RecInd'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:38.996891Z","iopub.execute_input":"2024-06-17T18:23:38.997339Z","iopub.status.idle":"2024-06-17T18:23:39.015014Z","shell.execute_reply.started":"2024-06-17T18:23:38.997299Z","shell.execute_reply":"2024-06-17T18:23:39.013922Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"RecInd\n3    376861\n7    275121\n5     80506\n6       928\n4         2\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"Instead of starting at 3, we're going to map it such that it starts at 0 and goes to 4. So 'scaling' our data. Unfortunately no meta data was provided for the dataset, so I'm not the most sure what this represents.","metadata":{}},{"cell_type":"code","source":"# mapping_dict = {3:0,\n#                 4:1,\n#                 5:2,\n#                 6:3,\n#                 7:4\n#                }\n# df['RecInd'] = df['RecInd'].map(mapping_dict)\n# df['RecInd'].head()\ndf = pd.get_dummies(df, columns=[\"RecInd\"],dtype=float)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:39.016420Z","iopub.execute_input":"2024-06-17T18:23:39.016783Z","iopub.status.idle":"2024-06-17T18:23:39.105994Z","shell.execute_reply.started":"2024-06-17T18:23:39.016755Z","shell.execute_reply":"2024-06-17T18:23:39.104885Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:39.107215Z","iopub.execute_input":"2024-06-17T18:23:39.107527Z","iopub.status.idle":"2024-06-17T18:23:39.132295Z","shell.execute_reply.started":"2024-06-17T18:23:39.107500Z","shell.execute_reply":"2024-06-17T18:23:39.131211Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   Cst_Cnt  Btl_Cnt  Depthm  T_degC  Salnty  STheta  T_prec  S_prec  NH3q  \\\n0        1        1       0   10.50   33.44  25.649     1.0     2.0   9.0   \n1        1        2       8   10.46   33.44  25.656     2.0     2.0   9.0   \n\n   C14A1q  C14A2q  DarkAq  MeanAq  R_Depth  R_TEMP  R_POTEMP  R_SALINITY  \\\n0     9.0     9.0     9.0     9.0      0.0   10.50     10.50       33.44   \n1     9.0     9.0     9.0     9.0      8.0   10.46     10.46       33.44   \n\n   R_SIGMA  R_SVA  R_DYNHT  R_PRES  RecInd_3  RecInd_4  RecInd_5  RecInd_6  \\\n0    25.64  233.0     0.00       0       1.0       0.0       0.0       0.0   \n1    25.65  232.5     0.01       8       1.0       0.0       0.0       0.0   \n\n   RecInd_7  \n0       0.0  \n1       0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cst_Cnt</th>\n      <th>Btl_Cnt</th>\n      <th>Depthm</th>\n      <th>T_degC</th>\n      <th>Salnty</th>\n      <th>STheta</th>\n      <th>T_prec</th>\n      <th>S_prec</th>\n      <th>NH3q</th>\n      <th>C14A1q</th>\n      <th>C14A2q</th>\n      <th>DarkAq</th>\n      <th>MeanAq</th>\n      <th>R_Depth</th>\n      <th>R_TEMP</th>\n      <th>R_POTEMP</th>\n      <th>R_SALINITY</th>\n      <th>R_SIGMA</th>\n      <th>R_SVA</th>\n      <th>R_DYNHT</th>\n      <th>R_PRES</th>\n      <th>RecInd_3</th>\n      <th>RecInd_4</th>\n      <th>RecInd_5</th>\n      <th>RecInd_6</th>\n      <th>RecInd_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.50</td>\n      <td>33.44</td>\n      <td>25.649</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>10.50</td>\n      <td>10.50</td>\n      <td>33.44</td>\n      <td>25.64</td>\n      <td>233.0</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>10.46</td>\n      <td>33.44</td>\n      <td>25.656</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>10.46</td>\n      <td>10.46</td>\n      <td>33.44</td>\n      <td>25.65</td>\n      <td>232.5</td>\n      <td>0.01</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# now lets use log function on our numerical features\nlog_int_cols = [col for col in df_int.columns if col != \"RecInd\"]\nfor col in log_int_cols:\n    df[col] = np.log1p(df[col])\ndf[\"R_Depth\"] = np.log1p(df[\"R_Depth\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:39.133828Z","iopub.execute_input":"2024-06-17T18:23:39.134164Z","iopub.status.idle":"2024-06-17T18:23:39.213678Z","shell.execute_reply.started":"2024-06-17T18:23:39.134137Z","shell.execute_reply":"2024-06-17T18:23:39.212403Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Preparing for Training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# splitting data into features and target values\nX = df.drop(columns=['T_degC']).values\ny = df['T_degC'].values","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:39.215096Z","iopub.execute_input":"2024-06-17T18:23:39.215444Z","iopub.status.idle":"2024-06-17T18:23:39.309018Z","shell.execute_reply.started":"2024-06-17T18:23:39.215415Z","shell.execute_reply":"2024-06-17T18:23:39.307855Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Split data into training and validation features\nX_train, X_val, t_train, t_val = train_test_split(X, y, test_size=0.1, random_state=17)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:23:39.310244Z","iopub.execute_input":"2024-06-17T18:23:39.310562Z","iopub.status.idle":"2024-06-17T18:23:39.616705Z","shell.execute_reply.started":"2024-06-17T18:23:39.310535Z","shell.execute_reply":"2024-06-17T18:23:39.615727Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Importance Normalization, and Standardization in Linear Regression\n\n\n### Normalization\nNormalization is the process of scaling data to fit within a specific range, typically [0, 1]. This is crucial for linear regression because it ensures that all features contribute equally to the model. Without normalization, features with larger ranges could dominate the regression model and skew the results. Min-max scaling is a common normalization technique.\n\n### Standardization\nStandardization scales data to have a mean of 0 and a standard deviation of 1. This process is essential for linear regression because it ensures that the model's weights are on a comparable scale, which can lead to more stable and faster convergence during training. Standardization is typically performed using z-score scaling.","metadata":{}},{"cell_type":"code","source":"numerical_columns = df.select_dtypes(include=[np.number]).columns","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:31.101341Z","iopub.execute_input":"2024-06-17T18:25:31.102285Z","iopub.status.idle":"2024-06-17T18:25:31.249472Z","shell.execute_reply.started":"2024-06-17T18:25:31.102245Z","shell.execute_reply":"2024-06-17T18:25:31.248368Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Normalizing numerical variables\ndef normalize_transform(X_train, X_val):\n    scaler = MinMaxScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_val_scaled = scaler.transform(X_val)\n\n    return X_train_scaled, X_val_scaled\n\nprint(\"Numerical variables normalized.\")\nX_train, X_val = normalize_transform(X_train, X_val)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:32.256547Z","iopub.execute_input":"2024-06-17T18:25:32.256963Z","iopub.status.idle":"2024-06-17T18:25:32.469916Z","shell.execute_reply.started":"2024-06-17T18:25:32.256928Z","shell.execute_reply":"2024-06-17T18:25:32.468805Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Numerical variables normalized.\n","output_type":"stream"}]},{"cell_type":"code","source":"# let's also standardize our data while we're at it\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data and transform the training data\nX_train = scaler.fit_transform(X_train)\n\n# Use the same scaler to transform the test data\nX_val = scaler.transform(X_val)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:34.421420Z","iopub.execute_input":"2024-06-17T18:25:34.422686Z","iopub.status.idle":"2024-06-17T18:25:34.764909Z","shell.execute_reply.started":"2024-06-17T18:25:34.422635Z","shell.execute_reply":"2024-06-17T18:25:34.763676Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Converting our training and validation data to pytorch tensors","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train, dtype=torch.float32)\nt_train = torch.tensor(t_train, dtype=torch.float32).view(-1, 1)\nX_val = torch.tensor(X_val, dtype=torch.float32)\nt_val = torch.tensor(t_val, dtype=torch.float32).view(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:36.594328Z","iopub.execute_input":"2024-06-17T18:25:36.594808Z","iopub.status.idle":"2024-06-17T18:25:39.429858Z","shell.execute_reply.started":"2024-06-17T18:25:36.594770Z","shell.execute_reply":"2024-06-17T18:25:39.428800Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# Defining Our Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\nclass TwoLayerRegressionModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(TwoLayerRegressionModel, self).__init__()\n        self.hidden = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.output = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, x):\n        x = self.hidden(x)\n        x = self.relu(x)\n        x = self.output(x)\n        return x\n\n# 25 input dim in our training set\ninput_dim = 25\nhidden_dim = 10\nmodel = TwoLayerRegressionModel(input_dim, hidden_dim)\n\n\n\n# Define loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:39.432109Z","iopub.execute_input":"2024-06-17T18:25:39.433405Z","iopub.status.idle":"2024-06-17T18:25:40.729144Z","shell.execute_reply.started":"2024-06-17T18:25:39.433357Z","shell.execute_reply":"2024-06-17T18:25:40.728006Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"# Training loop\nnum_epochs = 200\n\nfor epoch in range(num_epochs):\n    model.train()\n    \n    outputs = model(X_train)\n    loss = criterion(outputs, t_train)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:40.730378Z","iopub.execute_input":"2024-06-17T18:25:40.730901Z","iopub.status.idle":"2024-06-17T18:25:52.363555Z","shell.execute_reply.started":"2024-06-17T18:25:40.730868Z","shell.execute_reply":"2024-06-17T18:25:52.362408Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch [10/200], Loss: 28.4063\nEpoch [20/200], Loss: 12.8444\nEpoch [30/200], Loss: 5.7659\nEpoch [40/200], Loss: 2.1046\nEpoch [50/200], Loss: 0.8519\nEpoch [60/200], Loss: 0.5351\nEpoch [70/200], Loss: 0.4217\nEpoch [80/200], Loss: 0.3593\nEpoch [90/200], Loss: 0.3154\nEpoch [100/200], Loss: 0.2804\nEpoch [110/200], Loss: 0.2511\nEpoch [120/200], Loss: 0.2263\nEpoch [130/200], Loss: 0.2052\nEpoch [140/200], Loss: 0.1871\nEpoch [150/200], Loss: 0.1718\nEpoch [160/200], Loss: 0.1586\nEpoch [170/200], Loss: 0.1473\nEpoch [180/200], Loss: 0.1374\nEpoch [190/200], Loss: 0.1287\nEpoch [200/200], Loss: 0.1209\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluting Model","metadata":{}},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\nwith torch.no_grad():\n    predictions = model(X_val)\n    test_loss = criterion(predictions, t_val)\n    print(f'Test Loss: {test_loss.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:52.366366Z","iopub.execute_input":"2024-06-17T18:25:52.366995Z","iopub.status.idle":"2024-06-17T18:25:52.375107Z","shell.execute_reply.started":"2024-06-17T18:25:52.366949Z","shell.execute_reply":"2024-06-17T18:25:52.374044Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Test Loss: 0.1192\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Our training loss was always lower than our testing loss so it means our model wasn't over fitting yet and that we could continue to train it to squeeze even more preformance from it.","metadata":{}},{"cell_type":"markdown","source":"## Storing the Model in the System","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# save the model to disk\nmodel_filename = \"model.pkl\"\npickle.dump(model, open(model_filename, \"wb\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:52.376435Z","iopub.execute_input":"2024-06-17T18:25:52.376863Z","iopub.status.idle":"2024-06-17T18:25:52.383951Z","shell.execute_reply.started":"2024-06-17T18:25:52.376833Z","shell.execute_reply":"2024-06-17T18:25:52.382938Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Loading Model Back ","metadata":{}},{"cell_type":"code","source":"loaded_model = pickle.load(open(\"model.pkl\", \"rb\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:25:52.385141Z","iopub.execute_input":"2024-06-17T18:25:52.385461Z","iopub.status.idle":"2024-06-17T18:25:52.395907Z","shell.execute_reply.started":"2024-06-17T18:25:52.385429Z","shell.execute_reply":"2024-06-17T18:25:52.394733Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# doing an example prediction\n\n# switch to evaluation mode\nmodel.eval()\n\n# Generate Predictions:\nwith torch.no_grad():\n    prediction = model(X_val[2])\nprint(\"True value:\", t_val[2])\nprint(\"Predicted value:\", prediction)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:26:58.848454Z","iopub.execute_input":"2024-06-17T18:26:58.848943Z","iopub.status.idle":"2024-06-17T18:26:58.857964Z","shell.execute_reply.started":"2024-06-17T18:26:58.848907Z","shell.execute_reply":"2024-06-17T18:26:58.856694Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"True value: tensor([5.3800])\nPredicted value: tensor([5.2377])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Next Steps to Improve Preformance!\n- Increase training epochs to overfit model --> proves problem has a solution!\n- Consider adding dropout layers to reel the model back in.\n- Add in other columns with missing data to increase the amount of data the model has to look at\n- Change model capacity and parameters!\n- Fine tune model with Grid search or random search algorithms to find better hyperparameters.\n- Try out other models ex: Scikit learn Linear Regression model","metadata":{}}]}